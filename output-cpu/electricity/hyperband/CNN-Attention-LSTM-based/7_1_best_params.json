{
  "CNN-Attention-LSTM-based": {
    "lr": 0.001,
    "optimizer": "RMSprop",
    "l1_regularizer": 1e-05,
    "l2_regularizer": 1e-05,
    "min_delta": 1e-08,
    "patience": 35,
    "batch_size": 48,
    "filters": 64,
    "num_cnn_layers": 1,
    "num_lstm_layers": 1,
    "lstm_units": 150,
    "dropout": 0.4,
    "activation": "Tanh",
    "processing_time": "4.65 min"
  }
}