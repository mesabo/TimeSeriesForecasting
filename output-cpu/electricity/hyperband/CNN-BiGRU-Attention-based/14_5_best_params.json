{
  "CNN-BiGRU-Attention-based": {
    "lr": 0.0001,
    "optimizer": "RMSprop",
    "l1_regularizer": 0.0001,
    "l2_regularizer": 0.0001,
    "min_delta": 1e-08,
    "patience": 30,
    "batch_size": 32,
    "filters": 128,
    "kernel_size": 3,
    "pool_size": 1,
    "num_cnn_layers": 3,
    "num_bigru_layers": 1,
    "bigru_units": 100,
    "dropout": 0.2,
    "activation": "ReLU",
    "processing_time": "3.03 s"
  }
}